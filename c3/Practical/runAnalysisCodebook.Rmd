---
title: "Run Analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## To begin
Download the files and create a folder in the current directory call data if it does not exist

```{r}
#download data set
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
path <- file.path(getwd(),"data")
dPath <- file.path(getwd(),"")
f <- file.path("Dataset.zip")
if (!file.exists(path)) {dir.create(path)}
download.file(url, file.path(path, f))

# unzip the dataset
zipF<- file.path(path, f)
outDir <- file.path(getwd(),"data")
unzip(zipF,exdir=outDir)

```

## Load all the files just downloaded

For all the required files, import them into your environment as data tables.  You can think of these files as a set of rows and columns that all need to be combined.  Use the readme included in the downloaded files to learn more about what the data contains.

```{r}
# import all the dataset into variables.
# do some loggiing to understand the data
dtSubjectTrain <- fread(file.path(path, "UCI HAR Dataset/train", "subject_train.txt"))
dtSubjectTest  <- fread(file.path(path, "UCI HAR Dataset/test" , "subject_test.txt" ))

# not knowing how this data fits together
# checking col widhts and lengths to get some idea
# looking for common dimensions

length(dtSubjectTest$V1)
length(dtSubjectTrain$V1)


dtActivityYTrain <- fread(file.path(path, "UCI HAR Dataset/train", "y_train.txt"))
dtActivityYTest  <- fread(file.path(path, "UCI HAR Dataset/test", "y_test.txt" ))

dtActivityXTrain <- fread(file.path(path, "UCI HAR Dataset/train", "X_train.txt"))
dtActivityXTest  <- fread(file.path(path, "UCI HAR Dataset/test", "X_test.txt" ))


# not knowing this data fits together
# checking col widhts and lengths to get some idea
# looking for common dimensions
length(names(dtActivityYTest))
length(dtActivityXTest$V1)
length(dtActivityYTrain$V1)
```

## Load all the files just downloaded

I visualize this as a gaint excel spreadsheet.  In that sense you can think of pasting the data from the files into the cells. The order doesn't really matter so long as you end up the following results.

subjectTrain | activityTrain | Ytrain | Xtrain
----
subjectTest  | activityTest | Ytest  | Xtest

These names represent the content of files as one data table.

The feature row number in the features.txt files corespond to the columns found in the X data files.
The labels files numerically matches to the values in the activity column

```{r}
# the files are a mix of columns and rows

dtActivityTrain <- cbind(dtActivityYTrain, dtActivityXTrain)
dtActivityTest <- cbind(dtActivityYTest, dtActivityXTest)

# a one column data table, label the column subject
dtSubject <- rbind(dtSubjectTrain, dtSubjectTest)
setnames(dtSubject, "V1", "subject")

# a one column data table, label the column activityLabel
dtActivity <- rbind(dtActivityTrain,dtActivityTest)
setnames(dtActivity, 1, "activityLabel")
dt <- cbind(dtSubject, dtActivity);

setkey(dt, subject, activityLabel)

# import file as data table
activityLabels <- fread(file.path(path, "UCI HAR Dataset", "activity_labels.txt"))

# rename the columns to something descriptive
colnames(activityLabels)[1:2] <- c("activityLabel", "activityName")


# doing same thing for feature labels
# import features file as data table
features  <- fread(file.path(path, "UCI HAR Dataset", "features.txt" ))

# give helpful column names to the feature data table
colnames(features)[1:2] <- c("featureNum", "featureName")

```

## merge in the feature and activity labels so that we can begin the tidy data process.

As described above we are relating the values in the feature and activity_labels file and inserting the text value names.  This way we can read more easily what the value is.  Another key step in this process is the melt command that transforms the data set so that every value that was in a column has it's own row.

```{r}
# regex to pulls out names with mean or std
# the tick here is that featureNum lines up with column number of the data set
features <- features[grepl("mean\\(\\)|std\\(\\)", featureName)]
# next we append the letter V to the row number value which matches the data set column names
features$featureCode <- features[, paste0("V", featureNum)]
summary(dt)


# convert the featureCode field to a Vector
select <- c(key(dt), features$featureCode)
# use the vector to select from the data set the matching columns
dt <- dt[, select, with=FALSE]
# we now have only the measurements on the mean and standard deviation
summary(dt)
# using the column label activityLabel we join the Descriptive names matching the numeric values
dt <- merge(dt, activityLabels, by="activityLabel", all.x=TRUE)
setkey(dt, subject, activityLabel, activityName)

# melt transforms the table using the set keys above.
dt <- data.table(melt(dt, key(dt), variable.name="featureCode"))
# so now every value that was in a column has it's own row
# now we add the feature number and feature name using merge
dt <- merge(dt, features[, list(featureNum, featureCode, featureName)], by="featureCode", all.x=TRUE)
# the result replaces the difficult to read Vnum which was the original value of the column heading
# with a more readable name and reference number

# addes new column with factors from the given column
dt$activity <- factor(dt$activityName)
dt$feature <- factor(dt$featureName)
```

## This next step in a more involved process of cleaning up the names.

There are 66 unique feature names, however, they are long and encoded with various meaning that is hard to read or understand.  Using Regex we go through and caterogize them further by adding new columns tht decode the meanings of the names in feature column.

```{r}

# addes new column with factors from the given column
dt$activity <- factor(dt$activityName)
dt$feature <- factor(dt$featureName)

# define function to apply regex search
grepthis <- function (regex) {
  grepl(regex, dt$feature)
}
# Clean up the data one step further by group the features by common properties
n <- 2
y <- matrix(seq(1, n), nrow=n)
# go through all the feature names if it starts with the let t label as time
# if it starts with letter f, label as Freq
x <- matrix(c(grepthis("^t"), grepthis("^f")), ncol=nrow(y))
dt$featDomain <- factor(x %*% y, labels=c("Time", "Freq"))

# label the Instrument type as either Accelerometer or Gyroscope by matching
# Acc or Gryo any place in the feature name
x <- matrix(c(grepthis("Acc"), grepthis("Gyro")), ncol=nrow(y))
dt$featInstrument <- factor(x %*% y, labels=c("Accelerometer", "Gyroscope"))

# label Acceleartion by either Body/Gravity using the pattern passed into grepthis
x <- matrix(c(grepthis("BodyAcc"), grepthis("GravityAcc")), ncol=nrow(y))
dt$featAcceleration <- factor(x %*% y, labels=c(NA, "Body", "Gravity"))

# label mean() / std() as Mean or SD
x <- matrix(c(grepthis("mean()"), grepthis("std()")), ncol=nrow(y))
dt$featVariable <- factor(x %*% y, labels=c("Mean", "SD"))

# label feature names containing Jerk as either NA or Jerk
dt$featJerk <- factor(grepthis("Jerk"), labels=c(NA, "Jerk"))

# label features with Mag in name as Magnitude
dt$featMagnitude <- factor(grepthis("Mag"), labels=c(NA, "Magnitude"))

n <- 3
y <- matrix(seq(1, n), nrow=n)
# using the matrix y create a vector of the grep results
x <- matrix(c(grepthis("-X"), grepthis("-Y"), grepthis("-Z")), ncol=nrow(y))
# with the grep result matix us this to label the feature as either X,Y or Z
dt$featAxis <- factor(x %*% y, labels=c(NA, "X", "Y", "Z"))

# lets make sure that we didn't miss any features.
# count the number of unique feature names in the features colunm
r1 <- nrow(dt[, .N, by=c("feature")])
# count the number of unqiue feature names we just created in the new columns
r2 <- nrow(dt[, .N, by=c("featDomain", "featAcceleration", "featInstrument", "featJerk", "featMagnitude", "featVariable", "featAxis")])
r1 == r2
# they are equal so we feel good
```

## Create final tidy data set

Finally we select out the data values using the new labels and preform count and aveage operations.

```{r}
# now set a key for the data table on each of the new columns that have awesome new names
setkey(dt, subject, activity, featDomain, featAcceleration, featInstrument, featJerk, featMagnitude, featVariable, featAxis)

# then use the key list to make a new table that has the average and total number or rows (count)
Tidy <- dt[, list(count = .N, average = mean(value)), by=key(dt)]
# the result is a table with a tidy data set?
summary(Tidy)
# write the tidy data set to a file
write.csv(Tidy, "tidy.csv", row.names=FALSE)

```
